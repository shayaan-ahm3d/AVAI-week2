{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5bn2caU2Yah"
      },
      "source": [
        "# **Super-Resolution with Deep Image Prior**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJohJIBJuCNv"
      },
      "source": [
        "# Load T4 GPU in Colab\n",
        "\n",
        "1. Set Runtime -> Change runtime type -> Under Hardware Accelerator select GPU in Google Colab\n",
        "\n",
        "2. Load GitHub resource"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpvTE-Gi2Yaj",
        "outputId": "8e4b64b4-f46a-470a-cd42-e1192a692cd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'AVAI-week2' already exists and is not an empty directory.\n",
            "mv: cannot stat 'AVAI-week2/*': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/shayaan-ahm3d/AVAI-week2\n",
        "!mv AVAI-week2/* ./"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2RZhmS52Yak"
      },
      "source": [
        "# Parameters of super resolution\n",
        "\n",
        "2.PLOT shows whether you want to see the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cQyf91op2Yak"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "from models import *\n",
        "\n",
        "import torch\n",
        "import torch.optim\n",
        "\n",
        "from skimage.metrics import peak_signal_noise_ratio\n",
        "from utils.denoising_utils import *\n",
        "\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark =True\n",
        "\n",
        "use_gpu = False\n",
        "\n",
        "if use_gpu:\n",
        "    dtype = torch.cuda.FloatTensor\n",
        "else:\n",
        "    dtype = torch.float32\n",
        "\n",
        "imsize =-1\n",
        "PLOT = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uOkfIgz2Yak"
      },
      "source": [
        "# Load the high resolution image and low resolution image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XCRQKdkJ2Yak"
      },
      "outputs": [],
      "source": [
        "from dataset import Div2kDataset, Mode\n",
        "from pathlib import Path\n",
        "\n",
        "from utils.common_utils import pil_to_np, np_to_pil, np_to_torch, torch_to_np\n",
        "from utils.sr_utils import crop_image\n",
        "\n",
        "#low_res_path = Path(\"dataset/DIV2K_train_LR_x8\")\n",
        "#high_res_path = Path(\"dataset/DIV2K_train_HR\")\n",
        "#dataset = Div2kDataset(low_res_path, high_res_path, Mode.TRAIN)\n",
        "\n",
        "high = Image.open(\"0001.png\")\n",
        "low = Image.open(\"0001x8.png\")\n",
        "\n",
        "low = crop_image(low)\n",
        "high = crop_image(high)\n",
        "\n",
        "low_np = pil_to_np(low)\n",
        "high_np = pil_to_np(high)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPgBHgcp2Yal"
      },
      "source": [
        "# Set up the parameters for training\n",
        "\n",
        "Main parameters\n",
        "\n",
        "1. **num_iter** controls the number of iterations for training\n",
        "\n",
        "2. **LR** controls the learning rate\n",
        "\n",
        "3. Two types of **optimizer** exists here. (1) **adam** (2)\n",
        " **LBFGS**\n",
        "\n",
        "In function **get_net**, there exists five types of Neural Network (1) **ResNet** (2) **skip** (3) **texture_nets** (4) **UNet** (5) **identity**\n",
        "\n",
        "\n",
        "Variable **mse** controls the type of loss here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwYKpZhz2Yal",
        "outputId": "33326b3f-7ddf-4403-eb63-d5250d68a78e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of params: 2184307\n"
          ]
        }
      ],
      "source": [
        "pad = 'reflection'\n",
        "OPT_OVER = 'net' # 'net,input'\n",
        "\n",
        "#training parameters\n",
        "reg_noise_std = 1./30.\n",
        "LR = 0.01\n",
        "\n",
        "OPTIMIZER='adam' # 'LBFGS'\n",
        "show_every = 100\n",
        "exp_weight=0.99\n",
        "\n",
        "num_iter = 500\n",
        "input_depth = 3\n",
        "figsize = 4\n",
        "\n",
        "INPUT = 'noise' # 'meshgrid'\n",
        "#Network structure\n",
        "net = get_net(input_depth, 'skip', pad,\n",
        "              skip_n33d=128,\n",
        "              skip_n33u=128,\n",
        "              skip_n11=4,\n",
        "              num_scales=5,\n",
        "              upsample_mode='bilinear').type(dtype)\n",
        "\n",
        "\n",
        "\n",
        "net_input = get_noise(input_depth, INPUT, (high.size[1], high.size[0])).type(dtype).detach()\n",
        "\n",
        "# Compute number of parameters\n",
        "s  = sum([np.prod(list(p.size())) for p in net.parameters()])\n",
        "print ('Number of params: %d' % s)\n",
        "\n",
        "# Loss\n",
        "mse = torch.nn.MSELoss().type(dtype)\n",
        "\n",
        "low_torch = np_to_torch(low_np).type(dtype)\n",
        "high_torch = np_to_torch(high_np).type(dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUKBXFUIx1zN"
      },
      "source": [
        "**Architecture of the Network of skip**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYhITZF3xjdF"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from models.common import *\n",
        "\n",
        "def skip(\n",
        "        num_input_channels=2, num_output_channels=3,\n",
        "        num_channels_down=[16, 32, 64, 128, 128], num_channels_up=[16, 32, 64, 128, 128], num_channels_skip=[4, 4, 4, 4, 4],\n",
        "        filter_size_down=3, filter_size_up=3, filter_skip_size=1,\n",
        "        need_sigmoid=True, need_bias=True,\n",
        "        pad='zero', upsample_mode='nearest', downsample_mode='stride', act_fun='LeakyReLU',\n",
        "        need1x1_up=True):\n",
        "    \"\"\"Assembles encoder-decoder with skip connections.\n",
        "\n",
        "    Arguments:\n",
        "        act_fun: Either string 'LeakyReLU|Swish|ELU|none' or module (e.g. nn.ReLU)\n",
        "        pad (string): zero|reflection (default: 'zero')\n",
        "        upsample_mode (string): 'nearest|bilinear' (default: 'nearest')\n",
        "        downsample_mode (string): 'stride|avg|max|lanczos2' (default: 'stride')\n",
        "\n",
        "    \"\"\"\n",
        "    assert len(num_channels_down) == len(num_channels_up) == len(num_channels_skip)\n",
        "\n",
        "    n_scales = len(num_channels_down)\n",
        "\n",
        "    if not (isinstance(upsample_mode, list) or isinstance(upsample_mode, tuple)) :\n",
        "        upsample_mode   = [upsample_mode]*n_scales\n",
        "\n",
        "    if not (isinstance(downsample_mode, list)or isinstance(downsample_mode, tuple)):\n",
        "        downsample_mode   = [downsample_mode]*n_scales\n",
        "\n",
        "    if not (isinstance(filter_size_down, list) or isinstance(filter_size_down, tuple)) :\n",
        "        filter_size_down   = [filter_size_down]*n_scales\n",
        "\n",
        "    if not (isinstance(filter_size_up, list) or isinstance(filter_size_up, tuple)) :\n",
        "        filter_size_up   = [filter_size_up]*n_scales\n",
        "\n",
        "    last_scale = n_scales - 1\n",
        "\n",
        "    cur_depth = None\n",
        "\n",
        "    model = nn.Sequential()\n",
        "    model_tmp = model\n",
        "\n",
        "    input_depth = num_input_channels\n",
        "    for i in range(len(num_channels_down)):\n",
        "\n",
        "        deeper = nn.Sequential()\n",
        "        skip = nn.Sequential()\n",
        "\n",
        "        if num_channels_skip[i] != 0:\n",
        "            model_tmp.add(Concat(1, skip, deeper))\n",
        "        else:\n",
        "            model_tmp.add(deeper)\n",
        "\n",
        "        model_tmp.add(bn(num_channels_skip[i] + (num_channels_up[i + 1] if i < last_scale else num_channels_down[i])))\n",
        "\n",
        "        if num_channels_skip[i] != 0:\n",
        "            skip.add(conv(input_depth, num_channels_skip[i], filter_skip_size, bias=need_bias, pad=pad))\n",
        "            skip.add(bn(num_channels_skip[i]))\n",
        "            skip.add(act(act_fun))\n",
        "\n",
        "        # skip.add(Concat(2, GenNoise(nums_noise[i]), skip_part))\n",
        "\n",
        "        deeper.add(conv(input_depth, num_channels_down[i], filter_size_down[i], 2, bias=need_bias, pad=pad, downsample_mode=downsample_mode[i]))\n",
        "        deeper.add(bn(num_channels_down[i]))\n",
        "        deeper.add(act(act_fun))\n",
        "\n",
        "        deeper.add(conv(num_channels_down[i], num_channels_down[i], filter_size_down[i], bias=need_bias, pad=pad))\n",
        "        deeper.add(bn(num_channels_down[i]))\n",
        "        deeper.add(act(act_fun))\n",
        "\n",
        "        deeper_main = nn.Sequential()\n",
        "\n",
        "        if i == len(num_channels_down) - 1:\n",
        "            # The deepest\n",
        "            k = num_channels_down[i]\n",
        "        else:\n",
        "            deeper.add(deeper_main)\n",
        "            k = num_channels_up[i + 1]\n",
        "\n",
        "        deeper.add(nn.Upsample(scale_factor=2, mode=upsample_mode[i]))\n",
        "\n",
        "        model_tmp.add(conv(num_channels_skip[i] + k, num_channels_up[i], filter_size_up[i], 1, bias=need_bias, pad=pad))\n",
        "        model_tmp.add(bn(num_channels_up[i]))\n",
        "        model_tmp.add(act(act_fun))\n",
        "\n",
        "\n",
        "        if need1x1_up:\n",
        "            model_tmp.add(conv(num_channels_up[i], num_channels_up[i], 1, bias=need_bias, pad=pad))\n",
        "            model_tmp.add(bn(num_channels_up[i]))\n",
        "            model_tmp.add(act(act_fun))\n",
        "\n",
        "        input_depth = num_channels_down[i]\n",
        "        model_tmp = deeper_main\n",
        "\n",
        "    model.add(conv(num_channels_up[0], num_output_channels, 1, bias=need_bias, pad=pad))\n",
        "    if need_sigmoid:\n",
        "        model.add(nn.Sigmoid())\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yO5CfnCu2Yal",
        "outputId": "0e758654-09ef-410c-b95a-85778dc1586c",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting optimization with ADAM\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "net_input_saved = net_input.detach().clone()\n",
        "noise = net_input.detach().clone()\n",
        "#smoothing image\n",
        "out_avg = net_input_saved\n",
        "\n",
        "#without smoothing\n",
        "#out_avg = None\n",
        "\n",
        "last_net = None\n",
        "psrn_noisy_last = 0\n",
        "\n",
        "i = 0\n",
        "def closure():\n",
        "    global i, out_avg, psrn_noisy_last, last_net, net_input\n",
        "\n",
        "    if reg_noise_std > 0:\n",
        "        net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
        "\n",
        "    out = net(net_input)\n",
        "\n",
        "    # Smoothing\n",
        "    if out_avg is None:\n",
        "        out_avg = out.detach()\n",
        "    else:\n",
        "        out_avg = out_avg * exp_weight + out.detach() * (1 - exp_weight)\n",
        "\n",
        "    #total_loss = mse(out, img_noisy_torch)\n",
        "    total_loss = mse(out, high_torch)\n",
        "    total_loss.backward()\n",
        "\n",
        "    #evaluation with psrn\n",
        "    psrn_noisy = peak_signal_noise_ratio(low_np, out.detach().cpu().numpy()[0])\n",
        "    psrn_gt    = peak_signal_noise_ratio(high_np, out.detach().cpu().numpy()[0])\n",
        "    psrn_gt_sm = peak_signal_noise_ratio(high_np, out_avg.detach().cpu().numpy()[0])\n",
        "\n",
        "    if  PLOT and i % 10 == 0:\n",
        "         print ('Iteration: ', i, ' Loss: ', total_loss.item(), ' PSRN_gt: ', psrn_gt, ' PSNR_gt_sm: ', psrn_gt_sm)\n",
        "    #print ('Iteration %05d    Loss %f   PSRN_gt: %f PSNR_gt_sm: %f' % (i, total_loss.item(), psrn_gt, psrn_gt_sm), '\\r', end='')\n",
        "    if  PLOT and i % show_every == 0:\n",
        "        #out_np = torch_to_np(out)\n",
        "        plot_image_grid([np.clip(low_np, 0, 1),\n",
        "                         np.clip(torch_to_np(out_avg), 0, 1)], factor=figsize, nrow=2)\n",
        "\n",
        "\n",
        "\n",
        "    # Backtracking\n",
        "    if i % show_every:\n",
        "        if psrn_noisy - psrn_noisy_last < -5:\n",
        "            print('Falling back to previous checkpoint.')\n",
        "\n",
        "            for new_param, net_param in zip(last_net, net.parameters()):\n",
        "                net_param.data.copy_(new_param.cuda())\n",
        "\n",
        "            return total_loss*0\n",
        "        else:\n",
        "            last_net = [x.detach().cpu() for x in net.parameters()]\n",
        "            psrn_noisy_last = psrn_noisy\n",
        "\n",
        "    i += 1\n",
        "\n",
        "    return total_loss\n",
        "\n",
        "p = get_params(OPT_OVER, net, net_input)\n",
        "optimize(OPTIMIZER, p, closure, LR, num_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37DuKDNxg6o9"
      },
      "source": [
        "# Show the result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "9MlXSZGz2Yal",
        "outputId": "9b67758a-239a-4b01-95d7-a65587d52e6d"
      },
      "outputs": [],
      "source": [
        "out_np = torch_to_np(net(net_input))\n",
        "q = plot_image_grid([np.clip(out_np, 0, 1), high_np], factor=13);"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
